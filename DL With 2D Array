package jiBand;

import java.io.BufferedReader;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.util.Arrays;
import java.util.Scanner;
import org.deeplearning4j.nn.api.OptimizationAlgorithm;
import org.deeplearning4j.nn.conf.BackpropType;
import org.deeplearning4j.nn.conf.MultiLayerConfiguration;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration;
import org.deeplearning4j.nn.conf.layers.LSTM;
import org.deeplearning4j.nn.conf.layers.RnnOutputLayer;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.deeplearning4j.nn.weights.WeightInit;
import org.deeplearning4j.optimize.listeners.ScoreIterationListener;
import org.json.simple.parser.ParseException;
import org.nd4j.evaluation.classification.Evaluation;
import org.nd4j.evaluation.regression.RegressionEvaluation;
import org.nd4j.linalg.activations.Activation;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.dataset.DataSet;
import org.nd4j.linalg.dataset.api.preprocessor.NormalizerStandardize;
import org.nd4j.linalg.factory.Nd4j;
import org.nd4j.linalg.learning.config.Adam;
import org.nd4j.linalg.lossfunctions.LossFunctions;

@SuppressWarnings("deprecation")
public class twoDArrayDL 
{
	private static final double learningRate = 1e-6;
	private static final double exponentialDecay1 = 0.9;
	private static final double exponentialDecay2 = 0.999;
	private static final double epsilon = 10e-8;
	private static final int miniBatchSize1 = 6540;
	private static final int miniBatchSize2 = 10218;
	private static final int nEpochs = 2;
	private static final int numInputs = 4;
	private static final int numOutputs = 4;
	private static final int numHiddenNodes = 3;
	private static final int labelIndex = 0;
	private static final int numClasses = 2;
	private static final int seed = 123;
	
	public static void main(String[] args) throws FileNotFoundException, IOException, ParseException 
	{
		int cCount = 4;		// declaring and instantiating a variable that stores the number of columns
		int rCount0;// declaring a variable that represents the number of rows
		int rCount1;
		int classes = 2;
	
		JuxtopiaDataConfig j = new JuxtopiaDataConfig();//declaring and instantiating the class juxtopia data config as variable j.
		FileLineCounter flc = new FileLineCounter();
		
		String strValue0 = j.getJIBandDataConfig("TRNF");	//declaring and instantiating a string variable to hold the path value taken from the data config method
        BufferedReader jet0 = new BufferedReader(new FileReader(strValue0));	//declaring and instantiating a buffered reader variable to store the content from the file
        rCount0 = flc.getFileLineCountB(jet0); 
        Scanner jetSC0 = new Scanner(System.in);
        jetSC0 = new Scanner(new FileReader(strValue0));
        double [][] dA0 = new double[rCount0][cCount];
        
        while (jetSC0.hasNextLine()) 
        {
        	 for (int row = 0; row < dA0.length; row++) 
	         {
	        	String[] r0 = jetSC0.nextLine().split(" ");
	            for (int column = 0; column < r0.length; column++) 
	            {
	               dA0[row][column] = Double.parseDouble(r0[column]);
	            }
	         }
        }
        
        String strValue1 = j.getJIBandDataConfig("TRNL");	
        BufferedReader jet1 = new BufferedReader(new FileReader(strValue1));	
        rCount1 = flc.getFileLineCountB(jet1);
        Scanner jetSC1 = new Scanner (System.in);
        jetSC1 = new Scanner (new FileReader(strValue1));
        double [][] dA1 = new double[rCount1][cCount];
        
        while (jetSC1.hasNextLine()) 
        {
        	 for (int row = 0; row < dA1.length; row++) 
	         {
	        	 String[] r1 = jetSC1.nextLine().split(" ");
	            for (int column = 0; column < r1.length; column++) 
	            {
	               dA1[row][column] = Double.parseDouble(r1[column]);
	            }
	         }
        } 
       
       INDArray trainingIN = Nd4j.create(dA0);
       INDArray trainingOUT = Nd4j.create(dA1);
       
       DataSet myData = new DataSet(trainingIN, trainingOUT);
       MultiLayerNetwork multiLayerNetwork = createModel(rCount0,classes );
       multiLayerNetwork.init();
       multiLayerNetwork.fit(myData);
/*       
       
     //normalizing the data
       NormalizerStandardize normalizer = new NormalizerStandardize(); //using the normalize standardize normalizer because we are not using image data and the range within the dimensions is not uniform.
       normalizer.fitLabel(true);
       normalizer.fit(trainData); 
       normalizer.transform(trainData);
       normalizer.fit(testData);
       normalizer.transform(testData);
 
*/
	//	System.out.println("Build model....");
       }
		private static MultiLayerNetwork createModel (int rCount, int classes) {
			// TODO Auto-generated method stub
		MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
				//random number generator that helps the program perform better when it comes to mapping the data.
				.seed(seed)
				//adam is a type of optimizer that combines the nest aspects of other gradient models. it is an adaptive rate learning method so it adapts based on the weights and the different parameters. 
				.updater(new Adam(learningRate, exponentialDecay1, exponentialDecay2, epsilon))
				.optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
				.updater(org.deeplearning4j.nn.conf.Updater.NESTEROVS)
				//a regularization method that adds information to solve ill-posed problems as well as preventing overfitting.
				.l2(1e-4)
				.list()
				.layer(0, new LSTM.Builder().nIn(numInputs).nOut(numHiddenNodes).activation(Activation.TANH).weightInit(WeightInit.RELU).build())
				.layer(1, new LSTM.Builder().nIn(numHiddenNodes).nOut(numHiddenNodes).activation(Activation.TANH).weightInit(WeightInit.RELU).build())
				.layer(2, new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT).nIn(numHiddenNodes).nOut(numOutputs).activation(Activation.SOFTMAX).weightInit(WeightInit.XAVIER).build()).build();//.backpropType(BackpropType.TruncatedBPTT).tBPTTLength(100).build();

	//creates multi-layer model object.
			MultiLayerNetwork model = new MultiLayerNetwork(conf);
			// initialize multi-layer network.
			model.init();
			model.setListeners(new ScoreIterationListener(20));
			return model;
		 }
}
